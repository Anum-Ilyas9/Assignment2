{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1jdpkp096eyLLNEl0Nw5kPE3FbuOK3jtG",
      "authorship_tag": "ABX9TyOeFyehcDWFwNbeZSKCK1C7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anum-Ilyas9/Assignment2/blob/main/Assignment1_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Discrepancies\n",
        "1. **Backbone Network**:\n",
        "   - Paper: HRNet (multi-resolution fusion).\n",
        "   - Implementation: ResNet101V2 (may lack fine-grained multi-resolution feature preservation).\n",
        "\n",
        "2. **Classifier**:\n",
        "   - Paper: DRBM + Softmax.\n",
        "   - Implementation: Dense layer with sigmoid (simpler but less powerful for complex multi-label tasks).\n",
        "\n",
        "3. **Preprocessing**:\n",
        "   - Paper: Circular cropping, CLAHE, noise removal.\n",
        "   - Implementation: Basic resizing and normalization.\n",
        "\n",
        "4. **Augmentation**:\n",
        "   - Paper: Comprehensive, addressing imbalances.\n",
        "   - Implementation: Likely less diverse.\n"
      ],
      "metadata": {
        "id": "c0YmIR0YAL88"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RHVLyXb_B7jw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.utils import Sequence\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab import drive\n",
        "import zipfile\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to the dataset zip file in Google Drive\n",
        "zip_file_path = '/content/drive/My Drive/Dataset.zip'  # Update this path\n",
        "\n",
        "# Extract the Dataset\n",
        "dataset_extract_path = './Dataset'\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(dataset_extract_path)\n",
        "    print(\"Dataset extracted!\")\n",
        "\n",
        "# Paths to annotations.csv and images folder within the dataset folder\n",
        "annotation_file_path = './Dataset/Dataset/annotation.csv'\n",
        "images_folder_path = './Dataset/Dataset/Images'\n",
        "\n",
        "# Load the Annotations File\n",
        "annotations = pd.read_csv(annotation_file_path)\n",
        "\n",
        "# Step 1: Data Cleaning - Remove Missing Files\n",
        "def filter_valid_annotations(annotations, images_folder):\n",
        "    valid_rows = []\n",
        "    for _, row in annotations.iterrows():\n",
        "        left_img_path = os.path.join(images_folder, row['Left-Fundus'])\n",
        "        right_img_path = os.path.join(images_folder, row['Right-Fundus'])\n",
        "        if os.path.exists(left_img_path) and os.path.exists(right_img_path):\n",
        "            valid_rows.append(row)\n",
        "        else:\n",
        "            print(f\"Missing files: {left_img_path} or {right_img_path}\")\n",
        "    return pd.DataFrame(valid_rows)\n",
        "\n",
        "annotations = filter_valid_annotations(annotations, images_folder_path)\n",
        "print(f\"Filtered annotations: {len(annotations)} rows remain.\")\n",
        "\n",
        "# Step 2: Extract Unique Classes and Map to Indices\n",
        "all_classes = set()\n",
        "for label_col in ['Left-Diagnostic Keywords', 'Right-Diagnostic Keywords']:\n",
        "    for label_str in annotations[label_col]:\n",
        "        classes = label_str.split(\",\")\n",
        "        all_classes.update([cls.strip() for cls in classes])\n",
        "\n",
        "class_to_index = {cls: idx for idx, cls in enumerate(sorted(all_classes))}\n",
        "num_labels = len(class_to_index)\n",
        "print(\"Class to Index Mapping:\", class_to_index)\n",
        "\n",
        "# Step 3: Preprocessing - Normalize, Shuffle, and Split Data\n",
        "def preprocess_annotations(annotations, class_to_index):\n",
        "    processed_data = []\n",
        "    for _, row in annotations.iterrows():\n",
        "        left_img_path = os.path.join(images_folder_path, row['Left-Fundus'])\n",
        "        right_img_path = os.path.join(images_folder_path, row['Right-Fundus'])\n",
        "\n",
        "        # Combine left and right diagnostic keywords\n",
        "        label_strs = row['Left-Diagnostic Keywords'] + ',' + row['Right-Diagnostic Keywords']\n",
        "        multi_hot = np.zeros(len(class_to_index), dtype=np.float32)\n",
        "        for label in label_strs.split(\",\"):\n",
        "            multi_hot[class_to_index[label.strip()]] = 1.0\n",
        "\n",
        "        processed_data.append([left_img_path, right_img_path, multi_hot])\n",
        "    return processed_data\n",
        "\n",
        "processed_data = preprocess_annotations(annotations, class_to_index)\n",
        "processed_data = shuffle(processed_data, random_state=42)\n",
        "\n",
        "# Train-Validation Split\n",
        "train_data, val_data = train_test_split(processed_data, test_size=0.2, random_state=42)\n",
        "print(f\"Training samples: {len(train_data)}, Validation samples: {len(val_data)}\")\n",
        "\n",
        "# Step 4: Custom Data Generator with Augmentation\n",
        "class PairedDataGenerator(Sequence):\n",
        "    def __init__(self, data, batch_size, target_size):\n",
        "        self.data = data\n",
        "        self.batch_size = batch_size\n",
        "        self.target_size = target_size\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.data) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_data = self.data[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        left_images, right_images, labels = [], [], []\n",
        "\n",
        "        for left_img_path, right_img_path, multi_hot in batch_data:\n",
        "            left_images.append(self.load_image(left_img_path))\n",
        "            right_images.append(self.load_image(right_img_path))\n",
        "            labels.append(multi_hot)\n",
        "\n",
        "        left_images = np.array(left_images)\n",
        "        right_images = np.array(right_images)\n",
        "        labels = np.array(labels)\n",
        "\n",
        "        return ({\"input_left\": left_images, \"input_right\": right_images}, labels)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        np.random.shuffle(self.data)\n",
        "\n",
        "    def load_image(self, path):\n",
        "        img = cv2.imread(path)\n",
        "        img = cv2.resize(img, self.target_size)\n",
        "        img = img / 255.0  # Normalize pixel values\n",
        "        return img\n",
        "\n",
        "# Parameters\n",
        "batch_size = 32\n",
        "target_size = (224, 224)\n",
        "\n",
        "# Load Training and Validation Generators\n",
        "train_generator = PairedDataGenerator(train_data, batch_size=batch_size, target_size=target_size)\n",
        "val_generator = PairedDataGenerator(val_data, batch_size=batch_size, target_size=target_size)\n",
        "\n",
        "# Debugging: Inspect a single batch\n",
        "batch = train_generator[0]\n",
        "print(\"Batch inputs:\", batch[0].keys())\n",
        "print(\"Left input shape:\", batch[0]['input_left'].shape)\n",
        "print(\"Right input shape:\", batch[0]['input_right'].shape)\n",
        "print(\"Labels shape:\", batch[1].shape)\n",
        "print(\"First label (multi-hot):\", batch[1][0])\n",
        "\n",
        "# Build Backbone Network\n",
        "def build_backbone():\n",
        "    backbone = tf.keras.applications.ResNet101V2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    backbone.trainable = False\n",
        "    return backbone\n",
        "\n",
        "# SENet Block\n",
        "def senet_block(input_tensor, reduction_ratio=16):\n",
        "    filters = input_tensor.shape[-1]\n",
        "    se = layers.GlobalAveragePooling2D()(input_tensor)\n",
        "    se = layers.Dense(filters // reduction_ratio, activation='relu')(se)\n",
        "    se = layers.Dense(filters, activation='sigmoid')(se)\n",
        "    se = layers.multiply([input_tensor, se])\n",
        "    return se\n",
        "\n",
        "# Attention Block\n",
        "def attention_block(input_tensor):\n",
        "    attention = layers.Conv2D(filters=input_tensor.shape[-1], kernel_size=(3, 3), padding='same')(input_tensor)\n",
        "    attention = layers.ReLU()(attention)\n",
        "    attention = layers.BatchNormalization()(attention)\n",
        "    return layers.add([input_tensor, attention])\n",
        "\n",
        "# Classification Network\n",
        "def build_classifier(output_units):\n",
        "    model = models.Sequential([\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(output_units, activation='sigmoid')  # Multi-label classification\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Full Fundus-DeepNet Model\n",
        "def build_fundus_deepnet(output_units):\n",
        "    input_left = layers.Input(shape=(224, 224, 3), name=\"input_left\")\n",
        "    input_right = layers.Input(shape=(224, 224, 3), name=\"input_right\")\n",
        "\n",
        "    # Backbone for feature extraction\n",
        "    backbone = build_backbone()\n",
        "    left_features = backbone(input_left)\n",
        "    right_features = backbone(input_right)\n",
        "\n",
        "    # Attention and SENet blocks\n",
        "    left_features = attention_block(left_features)\n",
        "    right_features = attention_block(right_features)\n",
        "\n",
        "    left_features = senet_block(left_features)\n",
        "    right_features = senet_block(right_features)\n",
        "\n",
        "    # Feature fusion\n",
        "    fused_features = layers.multiply([left_features, right_features])\n",
        "\n",
        "    # Classifier\n",
        "    classifier = build_classifier(output_units)\n",
        "    output = classifier(fused_features)\n",
        "\n",
        "    # Build and compile the model\n",
        "    model = models.Model(inputs={\"input_left\": input_left, \"input_right\": input_right}, outputs=output)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Training Function\n",
        "def train_model(model, train_generator, val_generator, epochs=5):\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "    history = model.fit(train_generator, validation_data=val_generator, epochs=epochs, callbacks=[early_stopping])\n",
        "    return history\n",
        "\n",
        "# Main Script to Train the Model\n",
        "model = build_fundus_deepnet(num_labels)\n",
        "history = train_model(model, train_generator, val_generator, epochs=5)\n",
        "\n",
        "# Save the Trained Model\n",
        "model.save('fundus_deepnet_model.h5')\n",
        "\n",
        "# Evaluate the Model\n",
        "test_loss, test_accuracy = model.evaluate(val_generator)\n",
        "print(f\"Test Accuracy: {test_accuracy}\")"
      ],
      "metadata": {
        "id": "-di-uF5LL5Pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Additional Metrics\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Get predictions\n",
        "predictions = model.predict(val_generator)\n",
        "predictions = (predictions > 0.5).astype(int)\n",
        "\n",
        "# Extract true labels\n",
        "true_labels = np.concatenate([batch[1] for batch in val_generator], axis=0)\n",
        "\n",
        "# Calculate metrics\n",
        "precision = precision_score(true_labels, predictions, average='macro')\n",
        "recall = recall_score(true_labels, predictions, average='macro')\n",
        "f1 = f1_score(true_labels, predictions, average='macro')\n",
        "\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "vxk3qvFTPEpz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}