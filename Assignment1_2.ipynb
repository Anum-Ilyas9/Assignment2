{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1jdpkp096eyLLNEl0Nw5kPE3FbuOK3jtG",
      "authorship_tag": "ABX9TyPkWtDPcF2gqS+HAQ95ORK6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anum-Ilyas9/Assignment2/blob/main/Assignment1_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Discrepancies\n",
        "1. **Backbone Network**:\n",
        "   - Paper: HRNet (multi-resolution fusion).\n",
        "   - Implementation: ResNet101V2 (may lack fine-grained multi-resolution feature preservation).\n",
        "\n",
        "2. **Classifier**:\n",
        "   - Paper: DRBM + Softmax.\n",
        "   - Implementation: Dense layer with sigmoid (simpler but less powerful for complex multi-label tasks).\n",
        "\n",
        "3. **Preprocessing**:\n",
        "   - Paper: Circular cropping, CLAHE, noise removal.\n",
        "   - Implementation: Basic resizing and normalization.\n",
        "\n",
        "4. **Augmentation**:\n",
        "   - Paper: Comprehensive, addressing imbalances.\n",
        "   - Implementation: Likely less diverse.\n"
      ],
      "metadata": {
        "id": "c0YmIR0YAL88"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RHVLyXb_B7jw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.utils import Sequence\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab import drive\n",
        "import zipfile\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to the dataset zip file in Google Drive\n",
        "zip_file_path = '/content/drive/My Drive/Dataset.zip'  # Update this path\n",
        "\n",
        "# Extract the Dataset\n",
        "dataset_extract_path = './Dataset'\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(dataset_extract_path)\n",
        "    print(\"Dataset extracted!\")\n",
        "\n",
        "# Path to annotations.csv and images folder within the dataset folder\n",
        "annotation_file_path = './Dataset/Dataset/annotation.csv'\n",
        "images_folder_path = './Dataset/Images'\n",
        "\n",
        "# Load the Annotations File\n",
        "annotations = pd.read_csv(annotation_file_path)\n",
        "\n",
        "# Filter annotations to include only rows with existing image files\n",
        "def filter_valid_annotations(annotations, images_folder):\n",
        "    valid_rows = []\n",
        "    for _, row in annotations.iterrows():\n",
        "        left_img_path = os.path.join(images_folder, row['Left-Fundus'])\n",
        "        right_img_path = os.path.join(images_folder, row['Right-Fundus'])\n",
        "        if os.path.exists(left_img_path) and os.path.exists(right_img_path):\n",
        "            valid_rows.append(row)\n",
        "        else:\n",
        "            print(f\"Missing files: {left_img_path} or {right_img_path}\")\n",
        "    return pd.DataFrame(valid_rows)\n",
        "\n",
        "# Clean the annotations DataFrame\n",
        "annotations = filter_valid_annotations(annotations, images_folder_path)\n",
        "print(f\"Filtered annotations: {len(annotations)} rows remain.\")\n",
        "\n",
        "# Extract unique classes from both diagnostic keyword columns\n",
        "all_classes = set()\n",
        "for label_col in ['Left-Diagnostic Keywords', 'Right-Diagnostic Keywords']:\n",
        "    for label_str in annotations[label_col]:\n",
        "        classes = label_str.split(\",\")  # Split multi-label strings\n",
        "        all_classes.update([cls.strip() for cls in classes])\n",
        "\n",
        "class_to_index = {cls: idx for idx, cls in enumerate(sorted(all_classes))}\n",
        "num_labels = len(class_to_index)\n",
        "print(\"Class to Index Mapping:\", class_to_index)\n",
        "\n",
        "# Custom Data Generator for Paired Inputs\n",
        "class PairedDataGenerator(Sequence):\n",
        "    def __init__(self, annotations, images_folder, batch_size, target_size, validation_split, subset, class_to_index):\n",
        "        self.annotations = annotations\n",
        "        self.images_folder = images_folder\n",
        "        self.batch_size = batch_size\n",
        "        self.target_size = target_size\n",
        "        self.validation_split = validation_split\n",
        "        self.subset = subset\n",
        "        self.class_to_index = class_to_index\n",
        "\n",
        "        # Split dataset into training and validation\n",
        "        self.data = self.annotations.sample(frac=1, random_state=42)  # Shuffle the dataset\n",
        "        val_split_idx = int(len(self.data) * (1 - self.validation_split))\n",
        "        if self.subset == 'training':\n",
        "            self.data = self.data.iloc[:val_split_idx]\n",
        "        elif self.subset == 'validation':\n",
        "            self.data = self.data.iloc[val_split_idx:]\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.data) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_data = self.data.iloc[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        left_images, right_images, labels = [], [], []\n",
        "\n",
        "        for _, row in batch_data.iterrows():\n",
        "            left_img_path = os.path.join(self.images_folder, row['Left-Fundus'])\n",
        "            right_img_path = os.path.join(self.images_folder, row['Right-Fundus'])\n",
        "\n",
        "            if os.path.exists(left_img_path) and os.path.exists(right_img_path):\n",
        "                left_images.append(self.load_image(left_img_path))\n",
        "                right_images.append(self.load_image(right_img_path))\n",
        "\n",
        "                # Combine left and right diagnostic keywords into a single multi-hot vector\n",
        "                label_strs = row['Left-Diagnostic Keywords'] + ',' + row['Right-Diagnostic Keywords']\n",
        "                multi_hot = np.zeros(len(self.class_to_index), dtype=np.float32)\n",
        "                for label in label_strs.split(\",\"):\n",
        "                    multi_hot[self.class_to_index[label.strip()]] = 1.0\n",
        "                labels.append(multi_hot)\n",
        "\n",
        "        left_images = np.array(left_images)\n",
        "        right_images = np.array(right_images)\n",
        "        labels = np.array(labels)\n",
        "\n",
        "        return ({\"input_left\": left_images, \"input_right\": right_images}, labels)\n",
        "\n",
        "    def load_image(self, path):\n",
        "        img = cv2.imread(path)\n",
        "        img = cv2.resize(img, self.target_size)\n",
        "        img = img / 255.0  # Normalize pixel values\n",
        "        return img\n",
        "\n",
        "# Parameters\n",
        "batch_size = 32\n",
        "target_size = (224, 224)\n",
        "\n",
        "# Load Training and Validation Data\n",
        "train_data = PairedDataGenerator(\n",
        "    annotations=annotations,\n",
        "    images_folder=images_folder_path,\n",
        "    batch_size=batch_size,\n",
        "    target_size=target_size,\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "    class_to_index=class_to_index\n",
        ")\n",
        "\n",
        "val_data = PairedDataGenerator(\n",
        "    annotations=annotations,\n",
        "    images_folder=images_folder_path,\n",
        "    batch_size=batch_size,\n",
        "    target_size=target_size,\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    class_to_index=class_to_index\n",
        ")\n",
        "\n",
        "# Debugging: Inspect a single batch\n",
        "batch = train_data[0]\n",
        "print(\"Batch inputs:\", batch[0].keys())\n",
        "print(\"Left input shape:\", batch[0]['input_left'].shape)\n",
        "print(\"Right input shape:\", batch[0]['input_right'].shape)\n",
        "print(\"Labels shape:\", batch[1].shape)\n",
        "print(\"First label (multi-hot):\", batch[1][0])\n",
        "\n",
        "# Build Backbone Network\n",
        "def build_backbone():\n",
        "    backbone = tf.keras.applications.ResNet101V2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    backbone.trainable = False\n",
        "    return backbone\n",
        "\n",
        "# SENet Block\n",
        "def senet_block(input_tensor, reduction_ratio=16):\n",
        "    filters = input_tensor.shape[-1]\n",
        "    se = layers.GlobalAveragePooling2D()(input_tensor)\n",
        "    se = layers.Dense(filters // reduction_ratio, activation='relu')(se)\n",
        "    se = layers.Dense(filters, activation='sigmoid')(se)\n",
        "    se = layers.multiply([input_tensor, se])\n",
        "    return se\n",
        "\n",
        "# Attention Block\n",
        "def attention_block(input_tensor):\n",
        "    attention = layers.Conv2D(filters=input_tensor.shape[-1], kernel_size=(3, 3), padding='same')(input_tensor)\n",
        "    attention = layers.ReLU()(attention)\n",
        "    attention = layers.BatchNormalization()(attention)\n",
        "    return layers.add([input_tensor, attention])\n",
        "\n",
        "# Classification Network\n",
        "def build_classifier(output_units):\n",
        "    model = models.Sequential([\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(output_units, activation='sigmoid')  # Multi-label classification\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Full Fundus-DeepNet Model\n",
        "def build_fundus_deepnet(output_units):\n",
        "    input_left = layers.Input(shape=(224, 224, 3), name=\"input_left\")\n",
        "    input_right = layers.Input(shape=(224, 224, 3), name=\"input_right\")\n",
        "\n",
        "    # Backbone for feature extraction\n",
        "    backbone = build_backbone()\n",
        "    left_features = backbone(input_left)\n",
        "    right_features = backbone(input_right)\n",
        "\n",
        "    # Attention and SENet blocks\n",
        "    left_features = attention_block(left_features)\n",
        "    right_features = attention_block(right_features)\n",
        "\n",
        "    left_features = senet_block(left_features)\n",
        "    right_features = senet_block(right_features)\n",
        "\n",
        "    # Feature fusion\n",
        "    fused_features = layers.multiply([left_features, right_features])\n",
        "\n",
        "    # Classifier\n",
        "    classifier = build_classifier(output_units)\n",
        "    output = classifier(fused_features)\n",
        "\n",
        "    # Build and compile the model\n",
        "    model = models.Model(inputs={\"input_left\": input_left, \"input_right\": input_right}, outputs=output)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Training Function\n",
        "def train_model(model, train_data, val_data, epochs=5):\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "    history = model.fit(train_data, validation_data=val_data, epochs=epochs, callbacks=[early_stopping])\n",
        "    return history\n",
        "\n",
        "# Main Script to Train the Model\n",
        "model = build_fundus_deepnet(num_labels)\n",
        "history = train_model(model, train_data, val_data, epochs=5)\n",
        "\n",
        "# Save the Trained Model\n",
        "model.save('fundus_deepnet_model.h5')\n",
        "\n",
        "# Evaluate the Model\n",
        "test_loss, test_accuracy = model.evaluate(val_data)\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n"
      ],
      "metadata": {
        "id": "-di-uF5LL5Pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Additional Metrics\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Get predictions\n",
        "predictions = model.predict(val_generator)\n",
        "predictions = (predictions > 0.5).astype(int)\n",
        "\n",
        "# Extract true labels\n",
        "true_labels = np.concatenate([batch[1] for batch in val_generator], axis=0)\n",
        "\n",
        "# Calculate metrics\n",
        "precision = precision_score(true_labels, predictions, average='macro')\n",
        "recall = recall_score(true_labels, predictions, average='macro')\n",
        "f1 = f1_score(true_labels, predictions, average='macro')\n",
        "\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "vxk3qvFTPEpz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}